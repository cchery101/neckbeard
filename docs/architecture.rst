Architecture
============

Anatomy of a Deploy
-------------------

When you run:

    $ neckbeard up

you kick off a complicated process involving gnomes and swamp gas.
Not really.
It's actually a straight-forward process that you probably want to understand
if you want to write Neckbeard Addons or contribute to development.

1. Configuration loading and validation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

First thing first,
the `neckbeard.loader:NeckbeardLoader` loads the JSON configuration files
you've stored in your `.neckbeard` directory
(or in whatever directory passed via `--configuration-directory`).
All of the files discussed in the `_configuration details`
are loaded from the file system,
their JSON is parsed,
and then certain required values are verified for consistency.

From there,
the `neckbeard.configuration:ConfigurationManager` combines these files
in order to build individual per-node configurations.
It does this one `environment` definition at a time by:

  * Bringing in matching `defaults` for all nodes with a configured `node_template`
  * Validating that nodes with a `node_template` provide values for any
    `required_overrides` defined by that `node_template`.
  * Building an environment-scoped context for both `environment.constants` and
    `environment.secrets` based on the configurations with matching environment
    `name`.
  * If a node provides a `seed_environment` option, then additional
    `seed_environment.constants` and `seed_environment.secrets` context is
    created from the matching environment sections in `constants.json` and
    `secrets.tpl`.
  * The `neckbeard.scale:ScalingManager` is consulted to determine how many
    nodes in each `scaling_group` are currently configured (which must be
    between the `minimum_count` and the `maximum_count`). This information is
    used to generate a `node` context for each of the nodes with a unique
    `node.scaling_group_index` counter.
  * For each node (including N nodes in each `scaling_group`), a configuration
    is generated by using Jinja2 template completion on each configuration
    value, passing in the `environment`, `seed_environment` and `node` context.
  * An environment configuration is generated, indicating which `addons` are
    available and what `redundancy_strategy` is in place.

2. Addon loading and validation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most powerful feature of Neckbeard is its well-defined addon interface,
and at this stage, it's time to let addons hook in.
The first task for all of the addons enabled via `neckbeard.json`
is to validate their relevant configuration for each node.
The `neckbeard.addons:AddonManager` receives the name-scoped section of a given
node's `addons` configuration,
along with the name-scoped section of the environments `addons` configuration,
along with the top-level `core` Neckbeard configuration.
Addons can then ensure that,
if enabled for that node,
all required configuration values exist
and are consistent.

3. Survey current node states and decide what is missing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Next, the `CoordinationManager` is used
via its configured `CoordinationBackend`
to take stock of what nodes are currently in operation.
This allows us to see which nodes that should exist,
currently don't exist.

4. Create new nodes and cloud resources
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* Gather backups and seed data
* Launch the resources
* Attach the data
* Modify their configuration to match (security groups, etc)

5. Determine provisioning order
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* Based on `redundancy_strategy`, decide the best order to do deployment
* Deploy in parallel where possible
* Take node health in to account, not just presence

6. Build app in preparation for release
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* Use buildpack API

7. Safely provision individual nodes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* Convert node configuration to Chef `roles` and `data_bags`
* Package up core Chef cookbooks and cookbooks from addons
* Tarball the whole thing plus the built app
* Push that to a node
* Run boto commands to take it out of operation (eg. out of a loadbalancer)
* Run chef-solo with the apropriate roles and data_bags
* Ensure it's healthy
* Put it back in operation

8. Log everything to backends
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


